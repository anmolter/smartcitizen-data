{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Batch dispersion analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Initialise session and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration file from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/src/config.yaml\n",
      "\u001b[32mLoaded configuration file\u001b[0m\n",
      "Loading devices data file from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/interim\n",
      "\u001b[32mTest initialisation done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import warnings                                  \n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.colors\n",
    "\n",
    "from src.data.data import *\n",
    "data = data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# INPUT DATA\n",
    "# Name of test to be analysed\n",
    "dispersion_test = '2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE'\n",
    "# How to export the files ('png' or 'fig' or None)\n",
    "type_file = None\n",
    "# Percentage of points to be considered NG sensor\n",
    "limit_errors = 3\n",
    "# Multiplier for std_dev (sigma) - Normal distribution (99.73%)\n",
    "limit_confidence_sigma = 3\n",
    "# t-student confidence level (%)\n",
    "t_confidence_level = 99\n",
    "# Use average dispersion or instantaneous\n",
    "use_instantatenous_dispersion = False\n",
    "# Min/max date for the analysis\n",
    "min_date = '2019-11-28'\n",
    "max_date = '2019-12-02'\n",
    "# In case there is a device with lower amount of channels, ignore the missing channels and keep going\n",
    "ignore_missing_channels = True\n",
    "# Smooth channels\n",
    "smooth_channels = True\n",
    "smooth_number = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test 2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE\n",
      "\u001b[33mNo alphasense specified in files for 10408\u001b[0m\n",
      "\u001b[33mNo alphasense specified in files for 10409\u001b[0m\n",
      "\u001b[33mNo alphasense specified in files for 10412\u001b[0m\n",
      "\u001b[33mNo alphasense specified in files for 10413\u001b[0m\n",
      "\u001b[33mNo alphasense specified in files for 10414\u001b[0m\n",
      "\u001b[33mNo alphasense specified in files for 10420\u001b[0m\n",
      "\u001b[33mNo alphasense specified in files for 10421\u001b[0m\n",
      "\u001b[33mNo alphasense specified in files for 10422\u001b[0m\n",
      "\u001b[32mLoaded cached info file\u001b[0m\n",
      "Loading device 9974\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 9974\n",
      "Device 9974 has last reading at 2019-11-26T15:35:07Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/9974.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 9974 has been loaded\u001b[0m\n",
      "Loading device 10408\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10408\n",
      "Device 10408 has last reading at 2019-12-02T18:01:10Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10408.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10408 has been loaded\u001b[0m\n",
      "Loading device 10409\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10409\n",
      "Device 10409 has last reading at 2019-12-02T18:00:53Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10409.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10409 has been loaded\u001b[0m\n",
      "Loading device 10412\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10412\n",
      "Device 10412 has last reading at 2019-12-02T18:01:00Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10412.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10412 has been loaded\u001b[0m\n",
      "Loading device 10413\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10413\n",
      "Device 10413 has last reading at 2019-12-02T18:01:38Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10413.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10413 has been loaded\u001b[0m\n",
      "Loading device 10414\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10414\n",
      "Device 10414 has last reading at 2019-12-02T18:00:52Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10414.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10414 has been loaded\u001b[0m\n",
      "Loading device 10420\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10420\n",
      "Device 10420 has last reading at 2019-12-02T18:00:58Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10420.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10420 has been loaded\u001b[0m\n",
      "Loading device 10421\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10421\n",
      "Device 10421 has last reading at 2019-12-02T18:01:17Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10421.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10421 has been loaded\u001b[0m\n",
      "Loading device 10422\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10422\n",
      "Device 10422 has last reading at 2019-12-02T18:01:00Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10422.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10422 has been loaded\u001b[0m\n",
      "Loading device 10423\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10423\n",
      "Device 10423 has last reading at 2019-11-22T09:52:47Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10423.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10423 has been loaded\u001b[0m\n",
      "Loading device 10424\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10424\n",
      "Device 10424 has last reading at 2019-11-22T09:54:15Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10424.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10424 has been loaded\u001b[0m\n",
      "Loading device 10425\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10425\n",
      "Device 10425 has last reading at 2019-12-02T18:00:10Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10425.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10425 has been loaded\u001b[0m\n",
      "Loading device 10426\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10426\n",
      "Device 10426 has last reading at 2019-11-22T09:53:18Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10426.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10426 has been loaded\u001b[0m\n",
      "Loading device 10427\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10427\n",
      "Device 10427 has last reading at 2019-11-22T09:52:57Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10427.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10427 has been loaded\u001b[0m\n",
      "Loading device 10429\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10429\n",
      "Device 10429 has last reading at 2019-11-22T09:53:52Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10429.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10429 has been loaded\u001b[0m\n",
      "Loading device 10430\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10430\n",
      "Device 10430 has last reading at 2019-11-22T09:52:16Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10430.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10430 has been loaded\u001b[0m\n",
      "Loading device 10431\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10431\n",
      "Device 10431 has last reading at 2019-11-22T09:53:38Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10431.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10431 has been loaded\u001b[0m\n",
      "Loading device 10474\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10474\n",
      "Device 10474 has last reading at 2019-12-02T18:00:05Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10474.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10474 has been loaded\u001b[0m\n",
      "Loading device 10475\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10475\n",
      "Device 10475 has last reading at 2019-11-22T09:53:38Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10475.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10475 has been loaded\u001b[0m\n",
      "Loading device 10476\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10476\n",
      "Device 10476 has last reading at 2019-12-02T18:01:12Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10476.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10476 has been loaded\u001b[0m\n",
      "Loading device 10557\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10557\n",
      "Device 10557 has last reading at 2019-12-02T18:00:58Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10557.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10557 has been loaded\u001b[0m\n",
      "Loading device 10558\n",
      "\u001b[33mNo metadata found - skipping\u001b[0m\n",
      "Requesting last reading from API for device 10558\n",
      "Device 10558 has last reading at 2019-12-02T18:00:08Z\n",
      "Dropping NaN\n",
      "\u001b[32mLoaded cached files from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/processed/2019/11/2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE/cached/10558.csv\u001b[0m\n",
      "\u001b[32mNo need to load new data from API\u001b[0m\n",
      "\u001b[32mDevice 10558 has been loaded\u001b[0m\n",
      "\u001b[32mTest loaded successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data.load_test(dispersion_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "## Get list of common channels\n",
    "Displays a warning in case there is a device that has fewer channels than the rest. You can choose whether or not to ignore it or update the list of common channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Get list of common channels\n",
    "save_path = join(data.dataDirectory, 'export/figs', dispersion_test)\n",
    "# Test Path\n",
    "if not exists(save_path):\n",
    "    print ('Creating export directory:\\n{}'.format(save_path))\n",
    "    mkdir(save_path)\n",
    "\n",
    "list_channels = list()\n",
    "# Get list of devices\n",
    "list_devices = list(data.tests[dispersion_test].devices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Init list of common channels. Get the one that has the most\n",
    "list_channels = data.tests[dispersion_test].devices[list_devices[0]].readings.columns\n",
    "# Extract list of common channels\n",
    "len_channels = len(list_channels)\n",
    "\n",
    "for device in list_devices:\n",
    "    \n",
    "    if ignore_missing_channels: \n",
    "        # We don't reduce the list in case the new list is smaller\n",
    "        list_channels = list(set(list_channels) | set(data.tests[dispersion_test].devices[device].readings.columns))\n",
    "    else:\n",
    "        # We reduce it\n",
    "        list_channels = list(set(list_channels) & set(data.tests[dispersion_test].devices[device].readings.columns))\n",
    "\n",
    "    print ('Device {}'.format(device))\n",
    "    print ('\\tMin reading at {}'.format(data.tests[dispersion_test].devices[device].readings.index[0]))\n",
    "    #min_date_records = min(min_date_records, records.readings[dispersion_test]['devices'][device]['data'].index[0])\n",
    "    print ('\\tMax reading at {}'.format(data.tests[dispersion_test].devices[device].readings.index[-1]))\n",
    "    #max_date_records = min(max_date_records, records.readings[dispersion_test]['devices'][device]['data'].index[-1])\n",
    "    print ('\\tNumber of points {}'.format(len(data.tests[dispersion_test].devices[device].readings.index)))\n",
    "    ## Eliminate devices with no points\n",
    "    if (len(data.tests[dispersion_test].devices[device].readings.index) == 0):\n",
    "        print ('Droping device {} for insufficient data points'.format(device))\n",
    "        data.tests[dispersion_test].devices.pop(device)\n",
    "    # Check the number of channels    \n",
    "    elif len_channels != len(data.tests[dispersion_test].devices[device].readings.columns): \n",
    "        print(\"\\tWARNING: Device {} has {}. Current common list length is {}\".format(device, len(data.tests[dispersion_test].devices[device].readings.columns), len_channels))\n",
    "        len_channels = len(list_channels)\n",
    "        if ignore_missing_channels:\n",
    "            print (\"\\tIgnoring missing channels\")\n",
    "\n",
    "print('Final list of channels:\\n', list_channels)\n",
    "\n",
    "if min_date is not None: min_date = pd.to_datetime(min_date).tz_localize('UTC').tz_convert('Europe/Madrid')\n",
    "if max_date is not None: max_date = pd.to_datetime(max_date).tz_localize('UTC').tz_convert('Europe/Madrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "display(HTML('<h2>Data</h2>'))\n",
    "display(HTML('<p><strong>Test name:</strong><br> {}</p>'.format(dispersion_test)))\n",
    "display(HTML('<p><strong>Number of devices tested:</strong><br> {}</p>'.format(len(list_devices))))\n",
    "display(HTML('<p><strong>Test dates:</strong><br> {} - {}</p>'.format(min_date, max_date)))\n",
    "display(HTML('<p><strong>Test author(s):</strong><br> {}</p><hr>'.format('Óscar González - Victor Barberán')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Test\n",
    "\n",
    "### Fraunhofer delivery\n",
    "Devices with IDs ['10423', '10424', '10425', '10426', '10427', '10429', '10430', '10431']\n",
    "### ICS delivery:\n",
    "Devices with IDs 10474 to 10476\n",
    "### iSCAPE Stations: \n",
    "Devices with IDs ['10408', '10409', '10412', '10413', '10414', '10420', '10421', '10422']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list_isglobal = ['9974']\n",
    "list_fraunhofer = ['10423', '10424', '10475', '10426', '10427', '10429', '10430', '10431']\n",
    "list_ics = ['10474', '10425', '10476']\n",
    "list_ecopenta = ['10557', '10558']\n",
    "list_stations = ['10408', '10409', '10412', '10413', '10414', '10420', '10421', '10422']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "display(HTML('<h3>Test Explanation</h3>'))\n",
    "display(HTML('<p>The methods used in this analysis are subject to the low amount of devices tested, and in general, a <i>common sense</i> approach is applied. This means that the plots indicate only trends and highlight some (but not all) potential faulty devices.</p>'))\n",
    "display(HTML('<p>Below, the confidence intervals used are those of the normal distribution (meaningful for sample numbers >30) and of the t-student distribution.</p>'))\n",
    "display(HTML('<p>Conclusions are derived by analysing the data further and testing the devices for longer periods if needed. Please, also note that statistical significance cannot be inferred from these amounts of devices, so some assumptions for normality have to be accepted. Comments and further discussion are always welcome.</p>'))\n",
    "display(HTML('<p>Finally, the individual sensors components integrated in the Smart Citizen hardware have their own accuracies and dispersions, for which Smart Citizen cannot assume any liability other than trying to work with the most appropiate selection. The tests we perform are aimed to determine and assume any failures in the sensors and their integration within the Smart Citizen hardware. For more information, please check the <a href=\"https://docs.smartcitizen.me\">official documentation</a> and the datasheets of each of the sensors.</p>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list_devices = list_ics + list_ecopenta\n",
    "list_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "import traceback\n",
    "\n",
    "# Calculate the dispersion for the sensors present in the dataset\n",
    "dispersion_df = pd.DataFrame()\n",
    "dispersion_history = list()\n",
    "display(HTML('<h3>Warnings</h3>'))\n",
    "warning_displayed = False\n",
    "location = None\n",
    "\n",
    "for device in list_devices:\n",
    "    location_test = data.tests[dispersion_test].devices[device].location\n",
    "    if location_test is None: data.std_out (f'Device {device} has no location')\n",
    "    else:\n",
    "        if location is None: location = location_test\n",
    "        elif location_test != location: data.std_out (f'Device {device} has different location!')\n",
    "        \n",
    "for channel in list_channels:\n",
    "    list_columns = list()\n",
    "    if channel != 'BATT':\n",
    "        for device in list_devices:\n",
    "            if channel in data.tests[dispersion_test].devices[device].readings.columns and len(data.tests[dispersion_test].devices[device].readings.loc[:,channel]) >0 :\n",
    "                # Important to resample and bfill for unmatching measures\n",
    "                if smooth_channels:\n",
    "                    channel_new = data.tests[dispersion_test].devices[device].readings[channel].resample('1Min').bfill().rolling(window=smooth_number).mean()\n",
    "                    dispersion_df[channel + '-' + device] = channel_new[channel_new > 0]\n",
    "                else:\n",
    "                    dispersion_df[channel + '-' + device] = data.tests[dispersion_test].devices[device].readings[channel].resample('1Min').bfill()\n",
    "                \n",
    "                list_columns.append(channel + '-' + device)\n",
    "            else:\n",
    "                if device not in list_stations: continue\n",
    "                display(HTML('<p>WARNING: Device {} does not contain {}</p>'.format(device, channel)))\n",
    "                warning_displayed = True\n",
    "    try:\n",
    "        if dispersion_df.index.tzinfo is None: dispersion_df.index = dispersion_df.index.tz_localize('UTC').tz_convert(location)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        pass\n",
    "    \n",
    "    # Trim dataset to min and max dates (normally these tests are carried out with _minutes_ of differences)\n",
    "    if min_date is not None: dispersion_df = dispersion_df[dispersion_df.index > min_date]\n",
    "    if max_date is not None: dispersion_df = dispersion_df[dispersion_df.index < max_date]\n",
    "\n",
    "    # Calculate Metrics\n",
    "    dispersion_df[channel + '_AVG'] = dispersion_df.loc[:,list_columns].mean(skipna=True, axis = 1)\n",
    "    dispersion_df[channel + '_STD'] = dispersion_df.loc[:,list_columns].std(skipna=True, axis = 1)\n",
    " \n",
    "    # Calculate Metrics\n",
    "    dispersion_global = dispersion_df[channel + '_STD'].mean()\n",
    "    # print (dispersion_df.index[0], dispersion_df.index[-1], channel, dispersion_global)\n",
    "    dispersion_history.append([channel, dispersion_global])\n",
    "if not warning_displayed:\n",
    "    display(HTML('<p>All devices show similar amounts of data. No data loss concern</p>'.format(device, channel)))\n",
    "    \n",
    "# display(HTML('<h3>Sensor dispersion</h3>'))\n",
    "# display(HTML('<p>Below, the sensor dispersion for each channel is listed (units of each sensor)</p>'))\n",
    "# dispersion_history = tuple(dispersion_history)\n",
    "# display(HTML('<ul style=\"list-style-type:disc;\">'))\n",
    "# for item in dispersion_history:\n",
    "#     display(HTML('<li>{}: {}</li>'.format(item[0], item[1])))\n",
    "# display(HTML('</ul>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "display(HTML('<hr>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Internal notes:\n",
    "\n",
    "+ NG PM Sensors: 10408, 10409, 10413, 10420, 10425, 10429:\n",
    "    - 10425, 10429: replaced and tested for longer (from 11-11-2019 at 13:23 onwards)\n",
    "    - 10425 replaced again 20/11 -> goes for ICS, 10475 is now part of Fraunhofer\n",
    "    \n",
    "+ iSCAPE:\n",
    "    - 10408: pm sensor ??\n",
    "    - 10413: pm sensor A\n",
    "    - 10420: pm sensor A \n",
    "    - 10409: pm sensor B\n",
    "     \n",
    "    - Sensor resetting issue:\n",
    "        1. 10422 1 PM Disconnected (11-11 19h)\n",
    "        2. 10421 Gases Pro Board Disconnected (11-11 19h)\n",
    "        3. Added battery to 9994 (12-11 13h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "+ Devices show normal behaviour. Two warnings are displayed for the tVOC and eCO2 sensors, but are due to the sensor stabilisation period.\n",
    "+ One PM sensor was replaced prior to 17/Nov due to sensor malfunction and shows proper behaviour. The warning displayed for the PM_25 metric is not considered abnormal sensor behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "display(HTML('<hr>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Time Series Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "display(HTML('<h2>Time Series Plots</h2>'))\n",
    "if min_date is None: min_date_test = dispersion_df.index[-1] \n",
    "else: min_date_test = min_date\n",
    "if max_date is None: max_date_test = dispersion_df.index[-1] \n",
    "else: max_date_test = max_date\n",
    "display(HTML('Min Date available: {}'.format(min_date_test)))\n",
    "display(HTML('Max Date available: {}'.format(max_date_test)))\n",
    "list_channels_kit =  ['PRESS', 'CCS811_ECO2', 'EXT_PM_10', 'NOISE_A', 'TEMP', 'CCS811_VOCS', 'HUM', 'EXT_PM_1', 'LIGHT', 'EXT_PM_25']\n",
    "\n",
    "test_for_kit = True\n",
    "list_channels_plots = list_channels_kit if test_for_kit else list_channels\n",
    "\n",
    "# Ignore battery\n",
    "if 'BATT' in list_channels_plots: list_channels_plots.remove('BATT')\n",
    "dict_devices_tbr = dict()\n",
    "for item in list_channels_plots: dict_devices_tbr[item] = list()\n",
    "\n",
    "for channel in list_channels_plots:\n",
    "    if channel not in list_channels_plots and test_for_kit: continue\n",
    "    # Make subplot\n",
    "    list_columns = list()\n",
    "    fig, (ax1, ax2) = plot.subplots(nrows = 2, figsize= (15,10))\n",
    "    cmap = plot.cm.Reds\n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=limit_errors/2)\n",
    "    index = list_channels_plots.index(channel)+1\n",
    "    total_number = len(list_channels_plots)\n",
    "    display(HTML('<h3>({}/{}) - {} </h3>'.format(index, total_number, channel)))\n",
    "    \n",
    "    dispersion_avg = 0\n",
    "    limit_confidence_sigma = 0\n",
    "    for item in dispersion_history:\n",
    "        if channel == item[0]:\n",
    "            dispersion_avg = item[1]\n",
    "            \n",
    "    if len(list_devices)>30:\n",
    "        display(HTML('<p>Using Normal Distribution. Using limit for sigma confidence: {}'.format(limit_confidence_sigma)))\n",
    "        limit_confidence = limit_confidence_sigma\n",
    "        # Calculate upper and lower bounds\n",
    "        if (use_instantatenous_dispersion):\n",
    "            # For sensors with high variability in the measurements, it's better to use this (i.e. alphasense)\n",
    "            upper_bound = dispersion_df[channel + '_AVG'] + limit_confidence * dispersion_df[channel + '_STD']\n",
    "            lower_bound = dispersion_df[channel + '_AVG'] - abs(limit_confidence * dispersion_df[channel + '_STD'])\n",
    "        else:\n",
    "            upper_bound = dispersion_df[channel + '_AVG'] + limit_confidence * dispersion_avg\n",
    "            lower_bound = dispersion_df[channel + '_AVG'] - abs(limit_confidence * dispersion_avg)\n",
    "    else:\n",
    "        limit_confidence = t.interval(t_confidence_level/100.0, len(list_devices), loc=dispersion_df[channel + '_AVG'], scale=dispersion_avg)\n",
    "        display(HTML('<p>Using t-student Distribution</p>'))\n",
    "        upper_bound = limit_confidence[1]\n",
    "        lower_bound = limit_confidence[0]\n",
    "\n",
    "    dispersion_df[channel + '_MAX'] = dispersion_df.loc[:,list_columns].max(skipna=True, axis = 1)\n",
    "    dispersion_df[channel + '_MIN'] = dispersion_df.loc[:,list_columns].min(skipna=True, axis = 1)\n",
    "        \n",
    "    # print ('Plotting devices')\n",
    "    for device in list_devices:\n",
    "        name_column = channel + '-' + device \n",
    "        if name_column in dispersion_df.columns:\n",
    "            # Count how many times we go above the upper bound or below the lower one\n",
    "            count_problems_up = dispersion_df[name_column] > upper_bound\n",
    "            count_problems_down =  dispersion_df[name_column] < lower_bound\n",
    "            \n",
    "            # Count them\n",
    "            count_problems = [1 if (count_problems_up[i] or count_problems_down[i]) else 0 for i in range(len(count_problems_up))]\n",
    "            # print (channel, device, np.sum(count_problems), len(count_problems))\n",
    "            \n",
    "            # Add the trace in either\n",
    "            number_errors = np.sum(count_problems)\n",
    "            max_number_errors = len(count_problems)\n",
    "            \n",
    "            if number_errors/max_number_errors > limit_errors/100:\n",
    "                print (f'WARNING: Device {device} out of {limit_errors}% limit - {np.round(number_errors/max_number_errors*100, 1)}% out')\n",
    "                if device not in dict_devices_tbr[channel]: dict_devices_tbr[channel].append(device)\n",
    "                alpha = 1\n",
    "                ax1.plot(dispersion_df.index, \n",
    "                         dispersion_df[name_column], \n",
    "                         color = 'r',\n",
    "                         label = device, alpha = alpha)\n",
    "            else:\n",
    "                alpha = 1\n",
    "                color = 'g'\n",
    "                ax2.plot(dispersion_df.index, \n",
    "                         dispersion_df[name_column], \n",
    "                         color = color, \n",
    "                         label = device, alpha = alpha)\n",
    "        \n",
    "    # Add upper and low bound bound to subplot 1\n",
    "    ax1.plot(dispersion_df.index, dispersion_df[channel + '_AVG'],'b', label = 'Average', alpha = 0.6)\n",
    "    ax1.plot(dispersion_df.index, upper_bound, 'k', label = 'Upper-Bound', alpha = 0.6)\n",
    "    ax1.plot(dispersion_df.index, lower_bound, 'k',label = 'Lower-Bound', alpha = 0.6)\n",
    "    \n",
    "    # Format the legend\n",
    "    lgd1 = ax1.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    ax1.grid(True)\n",
    "    ax1.set_ylabel(channel + ' TBR')\n",
    "    ax1.set_xlabel('Time')\n",
    "    \n",
    "    # Add upper and low bound bound to subplot 2\n",
    "    ax2.plot(dispersion_df.index, dispersion_df[channel + '_AVG'],'b', label = 'Average', alpha = 0.6)\n",
    "    ax2.plot(dispersion_df.index, upper_bound, 'k', label = 'Upper-Bound', alpha = 0.6)\n",
    "    ax2.plot(dispersion_df.index, lower_bound, 'k',label = 'Lower-Bound', alpha = 0.6)\n",
    "    \n",
    "    # Format the legend\n",
    "    ax2.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    lgd2 = ax2.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    ax2.grid(True)\n",
    "    ax2.set_ylabel(channel + ' OK')\n",
    "    ax2.set_xlabel('Time')\n",
    "    \n",
    "    # Check file type to make the export\n",
    "    if type_file is not None: print ('Saving figure')\n",
    "    if type_file == 'fig':\n",
    "        pickle.dump(fig, open(save_path + '/' + dispersion_test + '_' + channel + '.fig.pickle', 'wb'))\n",
    "    elif type_file == 'png':\n",
    "        fig.savefig(save_path + '/' + dispersion_test + '_' + channel + '.png', dpi=300, trasnparent = True, bbox_extra_artists=(lgd1, lgd2), bbox_inches='tight' )\n",
    "\n",
    "    # Show plots     \n",
    "    plot.show()\n",
    "    display(HTML('<br>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(index = list_channels_plots)\n",
    "\n",
    "for item in dispersion_history:\n",
    "    summary_df.loc[item[0], 'Dispersion'] = item[1]\n",
    "    if item[0] != 'BATT':\n",
    "        summary_df.loc[item[0], 'Total Number of devices'] = len(list_devices)\n",
    "        summary_df.loc[item[0], 'TBR Number of devices'] = len(dict_devices_tbr[item[0]])\n",
    "        summary_df.loc[item[0], 'OK Number of devices'] = len(list_devices) - len(dict_devices_tbr[item[0]])\n",
    "    \n",
    "display (summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Further testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "plot_description = {\"plot_type\": \"timeseries\",\n",
    "                    \"plotting_library\": \"plotly\",\n",
    "                    \"data\": {\"test\": \"2019-11_INT_8_FRAUNHOFER_8_STATION_ISCAPE\",\n",
    "\t\t\t\t\t\t\t\t\t\"traces\": {\"1\": {\"device\": \"all\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\"channel\" : \"EXT_PM_25\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\"subplot\": 1}}},\n",
    "                    \"options\": {\"clean_na\": None,\n",
    "                                \"show_plot\": True,\n",
    "                                \"separate_device_plots\": False,\n",
    "                                \"export_path\": \"/Users/macoscar/Desktop\", \n",
    "                                \"file_name\": \"PM_SENSOR_ISSUE.png\",\n",
    "                                \"target_raster\": '10Min',\n",
    "                                \"max_date\": '2019-11-23',\n",
    "                                \"min_date\": '2019-11-17'},\n",
    "                    \"formatting\": {\"xlabel\": \"Date (-)\",\n",
    "                                   \"ylabel\": {1: \"EXT_PM_25\"},\n",
    "                                   \"yrange\": {1: [-10, 180]},\n",
    "                                   \"title\": \"EXT_PM_25 - PM Sensor issue\",\n",
    "                                   \"sharex\":True,\n",
    "                                   \"grid\": True,\n",
    "                                   \"height\": 10,\n",
    "                                   \"width\": 15}\n",
    "                    }\n",
    "\n",
    "from src.visualization.visualization import plot_wrapper\n",
    "\n",
    "plot_object = plot_wrapper(plot_description, False)\n",
    "plot_object.plot(records)\n",
    "plot_object.export_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "display(HTML('<h2>Time Series Plots</h2>'))\n",
    "display(HTML('Min Date available: {}'.format(min_date)))\n",
    "display(HTML('Max Date available: {}'.format(max_date)))\n",
    "        \n",
    "# Ignore battery\n",
    "if 'BATT' in list_channels: list_channels.remove('BATT')\n",
    "dict_devices_tbr = dict()\n",
    "for item in list_channels: dict_devices_tbr[item] = list()\n",
    "\n",
    "for channel in list_channels:\n",
    "    # Make subplot\n",
    "    list_columns = list()\n",
    "    fig, (ax1, ax2) = plot.subplots(nrows = 2, figsize= (15,10))\n",
    "    cmap = plot.cm.Reds\n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=limit_errors/2)\n",
    "    display(HTML('<h3>({}/{}) - {} </h3>'.format(list_channels.index(channel)+1, len(list_channels), channel)))\n",
    "    \n",
    "    dispersion_avg = 0\n",
    "    limit_confidence_sigma = 0\n",
    "    for item in dispersion_history:\n",
    "        if channel == item[0]:\n",
    "            dispersion_avg = item[1]\n",
    "            \n",
    "    if len(list_devices)>30:\n",
    "        display(HTML('<p>Using Normal Distribution. Using limit for sigma confidence: {}'.format(limit_confidence_sigma)))\n",
    "        limit_confidence = limit_confidence_sigma\n",
    "        # Calculate upper and lower bounds\n",
    "        if (use_instantatenous_dispersion):\n",
    "            # For sensors with high variability in the measurements, it's better to use this (i.e. alphasense)\n",
    "            upper_bound = dispersion_df[channel + '_AVG'] + limit_confidence * dispersion_df[channel + '_STD']\n",
    "            lower_bound = dispersion_df[channel + '_AVG'] - abs(limit_confidence * dispersion_df[channel + '_STD'])\n",
    "        else:\n",
    "            upper_bound = dispersion_df[channel + '_AVG'] + limit_confidence * dispersion_avg\n",
    "            lower_bound = dispersion_df[channel + '_AVG'] - abs(limit_confidence * dispersion_avg)\n",
    "    else:\n",
    "        limit_confidence = t.interval(t_confidence_level/100.0, len(list_devices), loc=dispersion_df[channel + '_AVG'], scale=dispersion_avg)\n",
    "        display(HTML('<p>Using t-student Distribution</p>'))\n",
    "        upper_bound = limit_confidence[1]\n",
    "        lower_bound = limit_confidence[0]\n",
    "\n",
    "    dispersion_df[channel + '_MAX'] = dispersion_df.loc[:,list_columns].max(skipna=True, axis = 1)\n",
    "    dispersion_df[channel + '_MIN'] = dispersion_df.loc[:,list_columns].min(skipna=True, axis = 1)\n",
    "        \n",
    "    # print ('Plotting devices')\n",
    "    for device in list_devices:\n",
    "        name_column = channel + '-' + device \n",
    "        if name_column in dispersion_df.columns:\n",
    "            # Count how many times we go above the upper bound or below the lower one\n",
    "            count_problems_up = dispersion_df[name_column] > upper_bound\n",
    "            count_problems_down =  dispersion_df[name_column] < lower_bound\n",
    "            \n",
    "            # Count them\n",
    "            count_problems = [1 if (count_problems_up[i] or count_problems_down[i]) else 0 for i in range(len(count_problems_up))]\n",
    "            # print (channel, device, np.sum(count_problems), len(count_problems))\n",
    "            \n",
    "            # Add the trace in either\n",
    "            number_errors = np.sum(count_problems)\n",
    "            max_number_errors = len(count_problems)\n",
    "            \n",
    "            if number_errors/max_number_errors > limit_errors/100:\n",
    "                print (f'WARNING: Device {device} out of {limit_errors}% limit - {np.round(number_errors/max_number_errors*100, 1)}% out')\n",
    "                if device not in dict_devices_tbr[channel]: dict_devices_tbr[channel].append(device)\n",
    "                alpha = 0.6\n",
    "                ax1.plot(dispersion_df.index, \n",
    "                         dispersion_df[name_column], \n",
    "                         color = cmap(norm(number_errors/max_number_errors*limit_errors)),\n",
    "                         label = device, alpha = alpha)\n",
    "            else:\n",
    "                alpha = 0.6\n",
    "                color = 'g'\n",
    "                ax2.plot(dispersion_df.index, \n",
    "                         dispersion_df[name_column], \n",
    "                         color = color, \n",
    "                         label = device, alpha = alpha)\n",
    "        \n",
    "    # Add upper and low bound bound to subplot 1\n",
    "    ax1.plot(dispersion_df.index, dispersion_df[channel + '_AVG'],'b', label = 'Average', alpha = 0.6)\n",
    "    ax1.plot(dispersion_df.index, upper_bound, 'k', label = 'Upper-Bound', alpha = 0.6)\n",
    "    ax1.plot(dispersion_df.index, lower_bound, 'k',label = 'Lower-Bound', alpha = 0.6)\n",
    "    \n",
    "    # Format the legend\n",
    "    lgd1 = ax1.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    ax1.grid(True)\n",
    "    ax1.set_ylabel(channel + ' TBR')\n",
    "    ax1.set_xlabel('Time')\n",
    "    \n",
    "    # Add upper and low bound bound to subplot 2\n",
    "    ax2.plot(dispersion_df.index, dispersion_df[channel + '_AVG'],'b', label = 'Average', alpha = 0.6)\n",
    "    ax2.plot(dispersion_df.index, upper_bound, 'k', label = 'Upper-Bound', alpha = 0.6)\n",
    "    ax2.plot(dispersion_df.index, lower_bound, 'k',label = 'Lower-Bound', alpha = 0.6)\n",
    "    \n",
    "    # Format the legend\n",
    "    ax2.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    lgd2 = ax2.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    ax2.grid(True)\n",
    "    ax2.set_ylabel(channel + ' OK')\n",
    "    ax2.set_xlabel('Time')\n",
    "    \n",
    "    # Check file type to make the export\n",
    "    if type_file is not None: print ('Saving figure')\n",
    "    if type_file == 'fig':\n",
    "        pickle.dump(fig, open(save_path + '/' + dispersion_test + '_' + channel + '.fig.pickle', 'wb'))\n",
    "    elif type_file == 'png':\n",
    "        fig.savefig(save_path + '/' + dispersion_test + '_' + channel + '.png', dpi=300, trasnparent = True, bbox_extra_artists=(lgd1, lgd2), bbox_inches='tight' )\n",
    "\n",
    "    # Show plots     \n",
    "    plot.show()\n",
    "    display(HTML('<br>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
